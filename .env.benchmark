# LLM Benchmark 공통 설정
# 이 파일은 vLLM과 TensorRT-LLM 양쪽에서 공통으로 사용되는 설정을 포함합니다

# 모델 설정
MODEL_NAME=Qwen3-8B
MODEL_DIR=/models/${MODEL_NAME}
DTYPE=bfloat16

# 성능 설정
MAX_BATCH_SIZE=256
MAX_INPUT_LEN=4096
MAX_SEQ_LEN=8192
MAX_NUM_TOKENS=8192

# GPU 설정
GPU_DEVICE_ID=0
GPU_MEMORY_UTILIZATION=0.9

# 서버 설정
SERVER_HOST=0.0.0.0
VLLM_PORT=8000
TENSORRT_PORT=8001

# 경로 설정
MODELS_PATH=/home/sewonkim/llm_models
ENGINES_BASE=/engines
CHECKPOINT_DIR=${ENGINES_BASE}/qwen3-8b/checkpoint
ENGINE_DIR=${ENGINES_BASE}/qwen3-8b/engine

# vLLM 전용 설정
VLLM_MAX_NUM_SEQS=32

# TensorRT-LLM 전용 설정
TENSORRT_TP_SIZE=1
TENSORRT_GEMM_PLUGIN=${DTYPE}
